Check stats, if you're sure you already ran stats then check stats twice.  It will show up as a warning towards the end of what I'd call the header of the profile.
Check file format: parquet/snappy is your goto, experiment with this only if you're out of other options or you know you're severely disk limited (gzip can help there, but it's rare).  Find this in the scan fragment, I usually search for "File Formats:"
Check the file/block size there are two places to look for this once in the explain plan where you'll see files=### size=###GB, and below in the scan fragments you'll see <volume id>:<# splits>/<split lengths> which is how to decode the following string, if split lengths are much less than what the block size should be investigate how you write the files.
Stop at just checking the block size, put down the set command.  I know it's tempting to change but it's unlikely to be the main problem. So long as you're starting with default 128MB (hive/spark) or 256MB (Impala) leave it until you've exhausted other options.
Check out the Execsummary, find the line that is taking the most time.
Is there skew?  Is the average time much lower than the max (unfortunately it will never be perfect, but anything more than 2x the average is usually definately skew of some sort, could be data sizes, the data itself, or a slow/faulty node if you always see one node being slow for various queries)
If you see something taking lots of time in the execsummary, do you have to do that step? 
If you have to do that step, can it be optimized? Is it a join that you can denormalize or make into a nested type?  Is it a complex case statement that can be run as part of ETL? View that you can materialize? Put on your thinking cap.
If you don't see any large times in the execsummary, check the query timeline right below it, do you see large startup time or for DML large metadata time?
Okay we checked a bunch of other things and didn't find anything. we should have a good idea of what's slow, is it the SCAN?  Alright now we can think about changing the block size, you can decrease the block size if you want to drive up parallelism (more files).  If you have many columns (usually >2-300) increasing the block size may help.
If you need to, dig deeper into the query fragments to see exactly why what's slow is slow, there are too many different metrics to list them out here, but use some intuition or if you're up to it go to the code and search for exactly what it's timing.  Keep in mind some times are wall time and some are CPU time, which is generally labelled.  Look for things that are off, like PerReadThreadRawHdfsThroughput < 100MB/s on a non-busy cluster. Keep in mind though there's a lot more to look at here than just one metric alone, and sometimes one part can look slow when another is the actual cause.