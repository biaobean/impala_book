

# 一、编译impala

## 1.1安装组件

以root用户登录hadoop001节点，安装组件



`yum install libevent-devel automake libtool flex bison gcc-c++ openssl-devel  make cmake doxygen.x86_64 glib-devel python-devel bzip2-devel svn libevent-devel cyrus-sasl-devel wget git unzip openldap-devel db4-devel`





## 1.2安装maven

1.下载maven包



以hadoop用户登录hadoop001节点，在家目录下下载maven包



cd ~

wget[**http://www.interior-dsgn.com/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz**](http://www.interior-dsgn.com/apache/maven/maven-3/3.0.5/binaries/apache-maven-3.0.5-bin.tar.gz)





2.移动软件包至安装目录下

mvapache-maven-3.0.5-bin.tar.gz /opt/beh/core/

3.解压软件包

cd /opt/beh/core/

tar -zxvf apache-maven-3.0.5-bin.tar.gz

4.删除软件包

rm apache-maven-3.0.5-bin.tar.gz

5.重命名目录

mv apache-maven-3.0.5 maven



6.配置环境变量

vi /etc/beh/conf/beh\_env

添加以下内容：

export M2\_HOME=/opt/beh/core/maven

export M2=$M2\_HOME/bin

export PATH=$M2:$PATH

7.source文件

source /etc/beh/conf/beh\_env

8.在当前目录下验证是否成功安装

mvn -version



## 1.3编译boost

1.删除旧版本boost

切换到root用户，用yum删除

su root

yum remove boost\*

su hadoop



2.将软件包从本地上传到家目录下之后转移到安装目录

mvboost\_1\_46\_0.tar.gz /opt/beh/core/

3.解压软件包

cd /opt/beh/core

tar -xvzf boost\_1\_46\_0.tar.gz

4.更改目录名称

mv boost\_1\_46\_0.tar.gz boost

5.删除软件包

rm boost\_1\_46\_0.tar.gz

6.编译安装

切换到root用户

su root

cd boost

./bootstrap.sh

./bjam --build-[**type**](http://cpro.baidu.com/cpro/ui/uijs.php?adclass=0&app_id=0&c=news&cf=1001&ch=0&di=128&fv=20&is_app=0&jk=d69315dc18698732&k=type&k0=type&kdi0=0&luki=5&mcpm=0&n=10&p=baidu&q=65035100_cpr&rb=0&rs=1&seller_id=1&sid=32876918dc1593d6&ssp2=1&stid=9&t=tpclicked3_hc&td=1836545&tu=u1836545&u=http://www.bubuko.com/infodetail-252619.html&urlid=0)=complete --[**layout**](http://cpro.baidu.com/cpro/ui/uijs.php?adclass=0&app_id=0&c=news&cf=1001&ch=0&di=128&fv=20&is_app=0&jk=d69315dc18698732&k=layout&k0=layout&kdi0=0&luki=7&mcpm=0&n=10&p=baidu&q=65035100_cpr&rb=0&rs=1&seller_id=1&sid=32876918dc1593d6&ssp2=1&stid=9&t=tpclicked3_hc&td=1836545&tu=u1836545&u=http://www.bubuko.com/infodetail-252619.html&urlid=0)=tagged --mt install



## 1.4编译llvm

1.下载源码

在hadoop家目录下下载安装包

wget[http://llvm.org/releases/3.3/llvm-3.3.src.tar.gz](http://llvm.org/releases/3.3/llvm-3.3.src.tar.gz)

2.将软件包移动到安装目录下并解压

mv llvm-3.3.src.tar.gz /opt/beh/core/

cd /opt/beh/core/

tar -xvzf llvm-3.3.src.tar.gz

3.更改路径名称

mv llvm-3.3.src.tar.gz llvm

4.删除压缩包

rm llvm-3.3.src.tar.gz

5.用svn来checkout



cd llvm-3.3.src/tools

svn co http://llvm.org/svn/llvm-project/cfe/tags/RELEASE\_33/final/ clang

cd ../projects

svn co http://llvm.org/svn/llvm-project/compiler-rt/tags/RELEASE\_33/final/ compiler-rt

6.编译

cd ..

./configure --with-pic

make -j4 REQUIRES\_RTTI=1

7.使用root用户安装

su root

make install

8.安装完成后切换回hadoop用户

su hadoop

## 1.5编译impala

1.下载源码

在家目录下用hadoop用户下载源码包

wget[http://archive.cloudera.com/cdh5/cdh/5/](http://archive.cloudera.com/cdh5/cdh/5/)



2.将源码包移动到安装目录

mvimpala-2.1.4-cdh5.3.5-src.tar.gz /opt/beh/core/

3.解压源码包

cd /opt/beh/core/

tar -zxvf impala-2.1.4-cdh5.3.5-src.tar.gz

4.更改目录名

mv impala-2.1.4-cdh5.3.5 impala

5.删除压缩包

rm impala-2.1.4-cdh5.3.5-src.tar.gz

6.更改编译版本

impala的编译脚本buildall.sh默认编译类型是debug版，我们选择编译release版

cd impala

vi buildall.sh

找到TARGET\_BUILD\_TYPE这行

将Debug改成Release

保存退出



cd impala

./buildall.sh -noclean -skiptests -so



注：如果有maven下包出现错误，应该是网络问题，重新更换网络，执行编译命令



# 二、部署impala

**\*\*\*该部分操作使用hadoop用户操作**

## 2.1更改本地集群配置文件

1.在hdfs-site.xml中添加

&lt;property&gt;

&lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;

&lt;value&gt;true&lt;/value&gt;

&lt;/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.domain.socket.path&lt;/name&gt;

&lt;value&gt;/var/lib/hadoop-hdfs/dn\_socket&lt;/value&gt;

&lt;/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;

&lt;value&gt;755&lt;/value&gt;

&lt;/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.block.local-path-access.user&lt;/name&gt;

&lt;value&gt;hadoop&lt;/value&gt;

&lt;/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.datanode.hdfs-blocks-metadata.enabled&lt;/name&gt;

&lt;value&gt;true&lt;/value&gt;

&lt;/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.client.file-block-storage-locations.timeout&lt;/name&gt;

&lt;value&gt;10000&lt;/value&gt;

&lt;/property&gt;

其中dfs.client.read.shortcircuit和 dfs.domain.socket.path为hdfs的短读属性，详细信息参见

http://note.youdao.com/share/web/file.html?id=fdc808678a8a9362fc3f8493babea5bc&type=note



2.在core-site.xml中添加

&lt;property&gt;

&lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;

&lt;value&gt;true&lt;/value&gt;

&lt;/property&gt;

&lt;property&gt;

&lt;name&gt;dfs.client.read.shortcircuit.skip.checksum&lt;/name&gt;

&lt;value&gt;false&lt;/value&gt;

&lt;/property&gt;



## 2.2删除impala自带配置文件样例

**使用hadoop用户操作**

**进入impala目录，删除impala自带的site.xml文件样例**

cd impala

find . -name core-site.xml

find . -name hdfs-site.xml

find . -name hive-site.xml

find . -name yarn-site.xml

find之后将这些配置文件删除

## 2.3拷贝配置文件

1.在impala目录下创建confmulu

cd /opt/beh/core/impala

mkdir conf

2.将之前修改过的本地集群上的配置文件core-site.xml

hdfs-site.xml以及hive-site.xml拷贝至conf目录下

cp /opt/beh/core/hadoop/etc/hadoop/core-site.xml conf/

cp /opt/beh/core/hadoop/etc/hadoop/hdfs-site.xml conf/

cp /opt/beh/core/hive/conf/hive-site.xml conf/

## 2.4建立so动态库目录

1.在impala目录下新建so目录

mkdir so

2.将impala当前目录下所有.so结尾的文件都复制到so目录下

find . -name '\*.so' \| xargs -i cp {} ./so

**注：在改命令在/opt/beh/core/impala/下执行**



3.将impala目录下的tests、testdata、thirtyparty三个目录删除

rm -rf test\*

rm -rf thirtyparty

## 2.5修改set-classpath.sh

vi bin/set-classpath.sh

1.在CLASSPATH中添加

$IMPALA\_HOME/conf:\

2.添加so动态库目录路径

export LD\_LIBRARY\_PATH=$LD\_LIBRARY\_PATH:$IMPALA\_HOME/so/

3.注释掉

\#for jar in \`ls ${IMPALA\_HOME}/testdata/target/dependency/\*.jar\`; do

\# CLASSPATH=${CLASSPATH}:$jar

\#done

这三行



## 2.6在start-statestore 中

vi bin/start-statestore.sh

1. 添加so动态库路径以及nohup功能

![](file://localhost/Users/biaochen/Library/Group%20Containers/UBF8T346G9.Office/msoclip1/01/clip_image002.png)2.在start-impalad.sh、start-catalogd添加nohup功能

![](file://localhost/Users/biaochen/Library/Group%20Containers/UBF8T346G9.Office/msoclip1/01/clip_image004.png)

![](file://localhost/Users/biaochen/Library/Group%20Containers/UBF8T346G9.Office/msoclip1/01/clip_image006.png)

## 2.7添加mysql驱动

将hive下的

hive/lib/mysql-connector-java-5.1.30.jar

拷贝到

impala /fe/target/dependency/下

cp /opt/beh/core/hive/lib/mysql-connector-java-5.1.30.jar impala /fe/target/dependency/

## 2.8添加impala环境变量

vi /opt/beh/conf/beh\_env

1.添加

export IMPALA\_HOME=$BEH\_HOME/core/impala

export IMPALA\_CONF\_DIR=$IMPALA\_HOME/conf

2.source /opt/beh/conf/beh\_env

# 三、将impala部署到集群其他机器上

## 3.1转移boost

1.切换到 root 用户下

su root

2.将本地boost库打包

find /usr/local -name '\*boost\*'

tar -czvf boostok.tgz /usr/local/lib/libboost\_\*

3.将boost包分发到其他节点上

scp boostok.tgz root@hadoop002:/opt/

scp boostok.tgz root@hadoop003:/opt/

scp boostok.tgz root@hadoop004:/opt/

4.到其他机器上解压

ssh hadoop002

cd /opt

tar -xzvf boostok.tgz -C /

hadoop003和hadoop004同上操作

5.查看一下两边boost包的数量是否一样

find /usr/local/lib -name 'libboost\*' \|wc -l

6.删除压缩包

rm boostok.tgz

7.切回hadoop用户

su hadoop

## 3.2转移llvm

1.切换到root用户

su root

2.将本地llvm打包

find /usr -name '\*llvm\*

tar -czvf llvmok.tgz /usr/local/bin/llvm\*

3.将llvm包分发到其他节点上

scp llvmok.tgz root@hadoop002:/opt/

scp llvmok.tgz root@hadoop003:/opt/

scp llvmok.tgz root@hadoop004:/opt/

4.到其他机器上解压

ssh hadoop002

cd /opt

tar -xzvf llvmok1.tgz -C /

hadoop003和hadoop004操作同上

5.删除压缩包

rm llvmok.tgz

6.切回hadoop用户

su hadoop

## 3.3转移impala

本操作使用hadoop用户

1.将本地impala打包

cd /opt/beh/core/

tar -jcvf impala-release.tar.bz2 impala

2.分发到其他节点上

scp impala-release.tar.bz2 hadoop@hadoop002:/opt/beh/core/

scp impala-release.tar.bz2 hadoop@hadoop003:/opt/beh/core/

scp impala-release.tar.bz2 hadoop@hadoop004:/opt/beh/core/

3.登录到其他节点上解压

ssh hadoop002

tar -jxvf impala-release.tar.bz2

4.删除压缩包

rm impala-release.tar.bz2

5.配置此节点环境变量

vi /opt/beh/cobf/beh\_env

1\)添加

export IMPALA\_HOME=$BEH\_HOME/core/impala

export IMPALA\_CONF\_DIR=$IMPALA\_HOME/conf

2\) source /opt/beh/cobf/beh\_env



# 四、启动impala

## 4.1需要进程

impala需要启动的进程：

statestore

catalog

impalad

其中statestore和catalog只需在其中一台节点启动即可，其他节点只需启动impalad进程

## 4.2启动命令

在impala目录下执行

cd /opt/beh/core/impala

启动statestore命令

./bin/start-statestored.sh

启动catalog命令

./bin/start-catalogd.sh





启动impalad命令

./bin/start-impalad.sh

## 4.3在要进行查询的节点上启动impala-shell

进入impala目录

./bin/impala-shell.sh



















